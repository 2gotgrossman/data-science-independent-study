{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/NYT_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vals = df.section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>headline</th>\n",
       "      <th>snippet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59f89f9895d0e0246f213289</td>\n",
       "      <td>Cynthia Nixon to Host the National Book Awards</td>\n",
       "      <td>Cynthia Nixon's new role will be on the bookis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59f89eb195d0e0246f213282</td>\n",
       "      <td>Borghese Gallery Gathers a Full House of Berni...</td>\n",
       "      <td>The most comprehensive exhibition of the Baroq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59f89c5795d0e0246f213277</td>\n",
       "      <td>‘Stranger Things 2’: Pixar’s Andrew Stanton on...</td>\n",
       "      <td>The director of “Finding Nemo” and “Wall-E” di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59f8972e95d0e0246f213265</td>\n",
       "      <td>Judge Accidentally Reveals Winner of Hot Bakin...</td>\n",
       "      <td>A judge on the Great British Bake Off, a widel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59f893bb95d0e0246f21325a</td>\n",
       "      <td>2 Best Friends in a Charming Aussie Comedy Abo...</td>\n",
       "      <td>It's time to make two new friends: Celia Pacqu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "0  59f89f9895d0e0246f213289   \n",
       "1  59f89eb195d0e0246f213282   \n",
       "2  59f89c5795d0e0246f213277   \n",
       "3  59f8972e95d0e0246f213265   \n",
       "4  59f893bb95d0e0246f21325a   \n",
       "\n",
       "                                            headline  \\\n",
       "0     Cynthia Nixon to Host the National Book Awards   \n",
       "1  Borghese Gallery Gathers a Full House of Berni...   \n",
       "2  ‘Stranger Things 2’: Pixar’s Andrew Stanton on...   \n",
       "3  Judge Accidentally Reveals Winner of Hot Bakin...   \n",
       "4  2 Best Friends in a Charming Aussie Comedy Abo...   \n",
       "\n",
       "                                             snippet  \n",
       "0  Cynthia Nixon's new role will be on the bookis...  \n",
       "1  The most comprehensive exhibition of the Baroq...  \n",
       "2  The director of “Finding Nemo” and “Wall-E” di...  \n",
       "3  A judge on the Great British Bake Off, a widel...  \n",
       "4  It's time to make two new friends: Celia Pacqu...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_df = df[['id', 'headline', 'snippet']]\n",
    "x_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up data: Remove all punctutation\n",
    "##### Note: This goes a little too far and makes \"it's\" become \"its\". Couldn't think of a good workaround"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(string):\n",
    "    if not (type(string) is str):\n",
    "        return ''\n",
    "    string = string.lower()\n",
    "    exclude = set('!@#$%^&*()-=_+1234567890{}[]|\\:;\"<,>./?`~\\'’')\n",
    "    return ''.join(ch for ch in string if ch not in exclude)\n",
    "headline = list(map(remove_punctuation, df.headline))\n",
    "snippet = list(map(remove_punctuation, df.snippet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining 'headline' and 'snippet' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_words = map(lambda x, y: set(x.split() + y.split()), \n",
    "                                  headline, snippet)\n",
    "tokenized_words = list(tokenized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'about', 'in', 'luke', 'friendship', 'two', 'a', 'its', 'charming', 'to', 'new', 'pacquola', 'comedy', 'time', 'celia', 'mcgregor', 'best', 'make', 'and', 'aussie', 'friends'}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_words[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/David/anaconda/envs/3.6default/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "x_df['tokenized_words'] = tokenized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>headline</th>\n",
       "      <th>snippet</th>\n",
       "      <th>tokenized_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59f89f9895d0e0246f213289</td>\n",
       "      <td>Cynthia Nixon to Host the National Book Awards</td>\n",
       "      <td>Cynthia Nixon's new role will be on the bookis...</td>\n",
       "      <td>{on, the, side, nixons, role, awards, to, cynt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59f89eb195d0e0246f213282</td>\n",
       "      <td>Borghese Gallery Gathers a Full House of Berni...</td>\n",
       "      <td>The most comprehensive exhibition of the Baroq...</td>\n",
       "      <td>{exhibition, around, borghese, of, maestro, mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59f89c5795d0e0246f213277</td>\n",
       "      <td>‘Stranger Things 2’: Pixar’s Andrew Stanton on...</td>\n",
       "      <td>The director of “Finding Nemo” and “Wall-E” di...</td>\n",
       "      <td>{project, pixars, discussed, ‘stranger, being,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59f8972e95d0e0246f213265</td>\n",
       "      <td>Judge Accidentally Reveals Winner of Hot Bakin...</td>\n",
       "      <td>A judge on the Great British Bake Off, a widel...</td>\n",
       "      <td>{forced, after, episode, revealing, competitio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59f893bb95d0e0246f21325a</td>\n",
       "      <td>2 Best Friends in a Charming Aussie Comedy Abo...</td>\n",
       "      <td>It's time to make two new friends: Celia Pacqu...</td>\n",
       "      <td>{about, in, luke, friendship, two, a, its, cha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "0  59f89f9895d0e0246f213289   \n",
       "1  59f89eb195d0e0246f213282   \n",
       "2  59f89c5795d0e0246f213277   \n",
       "3  59f8972e95d0e0246f213265   \n",
       "4  59f893bb95d0e0246f21325a   \n",
       "\n",
       "                                            headline  \\\n",
       "0     Cynthia Nixon to Host the National Book Awards   \n",
       "1  Borghese Gallery Gathers a Full House of Berni...   \n",
       "2  ‘Stranger Things 2’: Pixar’s Andrew Stanton on...   \n",
       "3  Judge Accidentally Reveals Winner of Hot Bakin...   \n",
       "4  2 Best Friends in a Charming Aussie Comedy Abo...   \n",
       "\n",
       "                                             snippet  \\\n",
       "0  Cynthia Nixon's new role will be on the bookis...   \n",
       "1  The most comprehensive exhibition of the Baroq...   \n",
       "2  The director of “Finding Nemo” and “Wall-E” di...   \n",
       "3  A judge on the Great British Bake Off, a widel...   \n",
       "4  It's time to make two new friends: Celia Pacqu...   \n",
       "\n",
       "                                     tokenized_words  \n",
       "0  {on, the, side, nixons, role, awards, to, cynt...  \n",
       "1  {exhibition, around, borghese, of, maestro, mo...  \n",
       "2  {project, pixars, discussed, ‘stranger, being,...  \n",
       "3  {forced, after, episode, revealing, competitio...  \n",
       "4  {about, in, luke, friendship, two, a, its, cha...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping each word to a number and then using that number to be an entry in an NxM matrix\n",
    "Where N is the number of observations and M is the number of times that word is present in that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_words = set()\n",
    "for words in x_df.tokenized_words:\n",
    "    unique_words.update(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index_map = {}\n",
    "index_to_word_map = []\n",
    "for i, word in enumerate(unique_words):\n",
    "    word_to_index_map[word] = i\n",
    "    index_to_word_map.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16990, 4)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_arr = np.zeros((x_df.shape[0], len(unique_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row, tokens in enumerate(x_df.tokenized_words):\n",
    "    for token in tokens:\n",
    "        col = word_to_index_map[token]\n",
    "        x_arr[row, col] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_vec = np.zeros((len(y_vals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = ['Arts', 'Business', 'Obituaries', 'Sports', 'World']\n",
    "def cat_to_number(cat):\n",
    "    return categories.index(cat)\n",
    "y_vec = np.array(list(map(cat_to_number, y_vals)) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 4, 4, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.random.choice(x_df.shape[0], x_df.shape[0] // 2, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = [x for x in range(x_df.shape[0]) if x not in x_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16990, 30926)\n",
      "(16990, 4)\n",
      "(5, 30926)\n",
      "8495\n"
     ]
    }
   ],
   "source": [
    "print(x_arr.shape)\n",
    "print(x_df.shape)\n",
    "word_count_by_class = np.zeros((5, x_arr.shape[1]))\n",
    "print(word_count_by_class.shape)\n",
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1455.]\n",
      " [ 1745.]\n",
      " [ 2017.]\n",
      " [ 1816.]\n",
      " [ 1462.]]\n",
      "(5, 30926)\n"
     ]
    }
   ],
   "source": [
    "train_set=x_train\n",
    "alpha=3\n",
    "beta=3\n",
    "\n",
    "num_features = x_arr.shape[1]\n",
    "num_obs = len(train_set)\n",
    "num_categories = 5\n",
    "\n",
    "obs_count_by_class = np.zeros((num_categories, 1))\n",
    "for i in train_set:\n",
    "    obs_count_by_class[y_vec[i], 0] += 1\n",
    "print(obs_count_by_class)\n",
    "theta_c = [count / len(train_set) for count in obs_count_by_class[:,0]]\n",
    "\n",
    "obs_count_by_class = obs_count_by_class + alpha + beta - 2\n",
    "\n",
    "word_count_by_class = np.zeros((num_categories, num_features))\n",
    "print(word_count_by_class.shape)\n",
    "for ix, i in enumerate(train_set):\n",
    "    word_count_by_class[y_vec[i], :] += x_arr[i, :]\n",
    "word_count_by_class = word_count_by_class + alpha - 1\n",
    "        \n",
    "theta_jc = np.zeros(word_count_by_class.shape)\n",
    "obs_count_by_class = np.tile(obs_count_by_class, (1, num_features))\n",
    "theta_jc = np.divide(word_count_by_class, obs_count_by_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17127722189523248, 0.20541494997057091, 0.23743378457916423, 0.21377280753384345, 0.17210123602118893]\n"
     ]
    }
   ],
   "source": [
    "print(theta_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_jc = np.zeros(theta_jc.shape)\n",
    "w_zeroc = np.zeros([1,num_categories])\n",
    "for i in range(num_categories):\n",
    "    for j in range(num_features):\n",
    "        w_jc[i, j] = math.log((theta_jc[i, j] * (1 - theta_jc[0, j])) / (theta_jc[0, j]*(1 - theta_jc[i, j])))\n",
    "        w_zeroc[0, i] += math.log((1 - theta_jc[i, j]) / (1 - \n",
    "                        theta_jc[0,j])) + math.log(theta_c[i] / theta_c[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 30926)\n",
      "[[     0.           5622.1002104   10106.96920755   6859.9363636\n",
      "     142.39831563]]\n"
     ]
    }
   ],
   "source": [
    "print(w_jc.shape)\n",
    "print(w_zeroc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2}\n"
     ]
    }
   ],
   "source": [
    "def predict(w_jc, w_zeroc, x_arr, y_vec, test_set):\n",
    "    num_categories = 5\n",
    "    num_features = x_arr.shape[1]\n",
    "    predictions = np.zeros((num_categories, len(test_set)))\n",
    "    for i,obs in enumerate(test_set):\n",
    "        for cat in range(num_categories):\n",
    "            predictions[cat, i] += np.sum(w_jc[cat, :]*x_arr[obs, :])\n",
    "            predictions[cat,i] += w_zeroc[0, cat]\n",
    "    return predictions\n",
    "\n",
    "predictions = predict(w_jc,w_zeroc, x_arr, y_vec, x_test)\n",
    "\n",
    "correct = 0\n",
    "s = set()\n",
    "for i, test_obs in enumerate(x_test):\n",
    "    s.add(np.argmax(predictions[: , i]))\n",
    "    correct += np.argmax(predictions[: , i]) == y_vec[test_obs]\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     0.              0.              0.         ...,      0.              0.\n",
      "       0.        ]\n",
      " [  5612.29681142   5618.14707852   5612.67352068 ...,   5611.27105936\n",
      "    5638.56216011   5623.14906878]\n",
      " [ 10097.55072354  10097.78839271  10105.33155527 ...,  10099.30836788\n",
      "   10106.03710634  10113.27915004]\n",
      " [  6849.98924013   6854.39310685   6854.49894121 ...,   6847.99172512\n",
      "    6862.6889999    6856.65044487]\n",
      " [   134.16022741    146.02413237    133.94002363 ...,    143.57414038\n",
      "     179.69790061    168.44941801]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:3.6default]",
   "language": "python",
   "name": "conda-env-3.6default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
